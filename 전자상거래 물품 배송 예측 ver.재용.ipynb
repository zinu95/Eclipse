{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#Classification Algorithms\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: delayed in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (0.11.0b1)\n",
      "Requirement already satisfied: hiredis in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from delayed) (2.0.0)\n",
      "Requirement already satisfied: redis in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from delayed) (3.5.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: wheel in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from lightgbm) (0.35.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from lightgbm) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from lightgbm) (0.24.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from lightgbm) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from xgboost) (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from xgboost) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"delivery/train.csv\", index_col='ID')\n",
    "X_test = pd.read_csv(\"delivery/test.csv\", index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Customer_care_calls'] = train['Customer_care_calls'].fillna(4.0)\n",
    "train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.iloc[:,-1:]\n",
    "X_train = train.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.drop(['Gender'],axis=1)\n",
    "X_test=X_test.drop(['Gender'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[(X_train.Weight_in_gms=='?'),'Weight_in_gms'] =3656\n",
    "X_test.loc[(X_test.Weight_in_gms=='?'),'Weight_in_gms'] =3656\n",
    "X_train['Weight_in_gms'] = X_train['Weight_in_gms'].astype(int)\n",
    "X_test['Weight_in_gms'] = X_test['Weight_in_gms'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8deaa5cb89284a2b9ebea8ca56cab21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a = set(X_train.columns) - set(X_test.columns)\n",
    "a = list(a)\n",
    "for i in tqdm(range(len(a))):\n",
    "    X_test[a[i]]= 0\n",
    "    tmp = X_train[a[i]]\n",
    "    X_train.drop(a[i],axis =1, inplace=True)\n",
    "    X_train = pd.concat([X_train,tmp],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3ddd81903d45c6ac5414b9ff81940e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "b = set(X_test.columns) - set(X_train.columns)\n",
    "b = list(b)\n",
    "for i in tqdm(range(len(b))):\n",
    "    X_train[b[i]]= 0\n",
    "    tmp = X_test[b[i]]\n",
    "    X_test.drop(b[i],axis =1, inplace=True)\n",
    "    X_test = pd.concat([X_test,tmp],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()   \n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hyperopt\n",
    "# from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "# reg_candidate = [1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1, 5, 10, 100]\n",
    "\n",
    "# space={'max_depth': hp.quniform(\"max_depth\", 3, 10, 1),\n",
    "#        'gamma': hp.uniform ('gamma', 0, 1),\n",
    "#        'learning_rate': hp.quniform ('learning_rate', 0.01, 0.05, 0.005),\n",
    "#        'reg_alpha' : hp.choice('reg_alpha', reg_candidate),\n",
    "#        'reg_lambda' : hp.choice('reg_lambda', reg_candidate),\n",
    "#        'subsample': hp.quniform('subsample', 0.6, 1, 0.05),\n",
    "#        'colsample_bytree' : hp.quniform('colsample_bytree', 0.6, 1, 0.05),\n",
    "#        'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "#        'n_estimators': hp.quniform('n_estimators', 300, 1500, 100)\n",
    "#       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# def hyperparameter_tuning(space):\n",
    "#     model=XGBClassifier(n_estimators =int(space['n_estimators']), \n",
    "#                        max_depth = int(space['max_depth']), \n",
    "#                        gamma = space['gamma'],\n",
    "#                        learning_rate = space['learning_rate'],\n",
    "#                        reg_alpha = space['reg_alpha'],\n",
    "#                        reg_lambda = space['reg_lambda'],\n",
    "#                        subsample = space['subsample'],\n",
    "#                        colsample_bytree = space['colsample_bytree'], \n",
    "#                        min_child_weight = int(space['min_child_weight']),\n",
    "#                        random_state=42, \n",
    "#                       )\n",
    "    \n",
    "#     evaluation = [(X_train, y_train), (X_test, y_test)]\n",
    "    \n",
    "#     model.fit(X_train, y_train,\n",
    "#               eval_set=evaluation, \n",
    "#               eval_metric=\"error\",\n",
    "#               early_stopping_rounds=30,\n",
    "#               verbose=0)\n",
    "\n",
    "#     pred = model.predict(X_test)\n",
    "#     error = mean_squared_error(y_test,pred)\n",
    "       \n",
    "#     #change the metric if you like\n",
    "#     return {'loss':error, 'status': STATUS_OK, 'model': model}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials = Trials()\n",
    "# best = fmin(fn=hyperparameter_tuning,\n",
    "#             space=space,\n",
    "#             algo=tpe.suggest,\n",
    "#             max_evals=100,\n",
    "#             trials=trials)\n",
    "# best['max_depth'] = int(best['max_depth'])\n",
    "# best['min_child_weight'] = int(best['min_child_weight'])\n",
    "# best['n_estimators'] = int(best['n_estimators'])\n",
    "# best['reg_alpha'] = reg_candidate[int(best['reg_alpha'])]\n",
    "# best['reg_lambda'] = reg_candidate[int(best['reg_lambda'])]\n",
    "# best['random_state'] = 123\n",
    "# print (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "# def print_all(model,X_train,X_test,y_train,y_test):\n",
    "#     model.fit(X_train,y_train)\n",
    "#     score = model.score(X_test,y_test)\n",
    "#     pred = model.predict(X_test)\n",
    "#     f1 = f1_score(pred,y_test)\n",
    "#     print(\"f1 : {:.5f}, Score : {:.3f}\".format(f1,score))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = XGBClassifier( n_estimators  = 600,\n",
    "                    learning_rate = 0.01, \n",
    "                    max_depth     = 4,\n",
    "                    random_state  = 11,\n",
    "                   # min_child_weight= 11, \n",
    "                    objective= 'binary:logistic', \n",
    "                    use_label_encoder = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-0.26-cp38-none-win_amd64.whl (68.4 MB)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from catboost) (1.1.3)\n",
      "Requirement already satisfied: graphviz in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from catboost) (0.16)\n",
      "Requirement already satisfied: six in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from catboost) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from catboost) (1.19.2)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.0.0-py2.py3-none-any.whl (19.1 MB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from catboost) (3.3.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-7.0.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Installing collected packages: tenacity, plotly, catboost\n",
      "Successfully installed catboost-0.26 plotly-5.0.0 tenacity-7.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "catboost = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    random_seed=42,\n",
    "    depth=4,\n",
    "    leaf_estimation_iterations=8,\n",
    "    learning_rate = 0.01,\n",
    "    logging_level= 'Silent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.683383340477211"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost.fit( X_train, y_train )\n",
    "catboost.score( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7002428918416916"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg.fit( X_train, y_train )\n",
    "xg.score( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=xg.predict(X_test)\n",
    "result=pd.read_csv('delivery/sampleSubmission.csv')\n",
    "result['Reached.on.Time_Y.N']=pre\n",
    "result.to_csv('sampleSubmission_02.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
